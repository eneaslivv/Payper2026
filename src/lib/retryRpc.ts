/**
 * RETRY RPC WRAPPER - Fix Riesgo #1
 *
 * Problema: NOWAIT locks en backend pueden fallar con LOCK_TIMEOUT
 * Si el frontend no reintenta, usuario ve error "fantasma" en hora pico
 *
 * Soluci√≥n: Retry autom√°tico con exponential backoff para LOCK_TIMEOUT
 *
 * Uso:
 * ```typescript
 * const { data, error } = await retryRpc(() =>
 *   supabase.rpc('adjust_inventory', { ... })
 * );
 * ```
 */

interface RetryOptions {
  maxRetries?: number;
  baseDelay?: number; // ms
  maxDelay?: number; // ms
  onRetry?: (attempt: number, error: any) => void;
  rpcName?: string; // Nombre del RPC para telemetr√≠a
}

const DEFAULT_OPTIONS: Required<RetryOptions> = {
  maxRetries: 3,
  baseDelay: 200,
  maxDelay: 2000,
  onRetry: () => {},
};

/**
 * Retry wrapper para RPCs de Supabase con lock handling + telemetr√≠a
 *
 * @param rpcCall - Funci√≥n que ejecuta el RPC
 * @param options - Opciones de retry
 * @returns Result del RPC con data/error
 */
export async function retryRpc<T>(
  rpcCall: () => Promise<{ data: T | null; error: any }>,
  options: RetryOptions = {}
): Promise<{ data: T | null; error: any }> {
  const opts = { ...DEFAULT_OPTIONS, ...options };
  const startTime = Date.now();

  for (let attempt = 0; attempt < opts.maxRetries; attempt++) {
    const { data, error } = await rpcCall();

    // ‚úÖ Success
    if (!error) {
      const duration = Date.now() - startTime;

      // Telemetr√≠a: Log m√©tricas de retry
      if (attempt > 0) {
        console.log(`[retryRpc] ‚úÖ Success after ${attempt + 1} attempts (${duration}ms)`);

        // Enviar a analytics (ahora habilitado)
        logRetryMetrics({
          rpc_name: opts.rpcName || 'unknown',
          attempts: attempt + 1,
          final_status: 'success',
          duration_ms: duration,
          error_code: null
        });
      }
      return { data, error: null };
    }

    // üîí LOCK_TIMEOUT espec√≠fico ‚Üí retry con backoff
    const isLockTimeout =
      error.code === '55P03' || // PostgreSQL lock_not_available
      error.code === 'PGRST301' || // PostgREST timeout
      error.message?.toLowerCase().includes('lock_timeout') ||
      error.message?.toLowerCase().includes('lock not available') ||
      error.error === 'LOCK_TIMEOUT'; // Custom RPC error

    if (isLockTimeout && attempt < opts.maxRetries - 1) {
      const delay = Math.min(
        opts.baseDelay * Math.pow(2, attempt),
        opts.maxDelay
      );

      console.warn(
        `[retryRpc] üîí LOCK_TIMEOUT detected, retry ${attempt + 1}/${opts.maxRetries} in ${delay}ms`
      );

      opts.onRetry(attempt + 1, error);

      await sleep(delay);
      continue; // Retry
    }

    // ‚ùå Otro error O max retries alcanzado ‚Üí fail
    if (attempt === opts.maxRetries - 1) {
      const duration = Date.now() - startTime;
      const errorCode = error.code || error.error || 'UNKNOWN';

      console.error(
        `[retryRpc] ‚ùå Failed after ${opts.maxRetries} attempts (${duration}ms):`,
        errorCode
      );

      // Telemetr√≠a: Log failure metrics
      logRetryMetrics({
        rpc_name: opts.rpcName || 'unknown',
        attempts: opts.maxRetries,
        final_status: 'failed',
        duration_ms: duration,
        error_code: errorCode
      });
    }

    return { data: null, error };
  }

  // Should never reach here
  return {
    data: null,
    error: { message: 'Max retries exceeded', code: 'MAX_RETRIES' },
  };
}

/**
 * Funci√≥n helper para logging de m√©tricas
 * Ahora conectado a tabla retry_metrics en Supabase
 */
async function logRetryMetrics(metrics: {
  rpc_name: string;
  attempts: number;
  final_status: 'success' | 'failed';
  duration_ms: number;
  error_code: string | null;
}) {
  try {
    // Lazy import para evitar circular dependency
    const { supabase } = await import('../../lib/supabase');

    // Enviar a Supabase analytics table (non-blocking)
    supabase.rpc('log_retry_metric', {
      p_rpc_name: metrics.rpc_name,
      p_attempts: metrics.attempts,
      p_final_status: metrics.final_status,
      p_duration_ms: metrics.duration_ms,
      p_error_code: metrics.error_code
    }).then(({ error }) => {
      if (error) {
        // Silent fail - no queremos que telemetr√≠a rompa la app
        console.debug('[retryRpc] Failed to log metric:', error.message);
      }
    });
  } catch (err) {
    // Silent fail - telemetr√≠a es best-effort
    console.debug('[retryRpc] Telemetry error:', err);
  }
}

/**
 * Sleep helper
 */
function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

/**
 * Retry espec√≠fico para stock operations (adjust, transfer, consume)
 * Muestra toast de "reintentando..." autom√°ticamente
 */
export async function retryStockRpc<T>(
  rpcCall: () => Promise<{ data: T | null; error: any }>,
  addToast?: (message: string, type: 'info' | 'error') => void,
  rpcName?: string
): Promise<{ data: T | null; error: any }> {
  return retryRpc(rpcCall, {
    maxRetries: 3,
    baseDelay: 300,
    maxDelay: 2000,
    rpcName: rpcName || 'stock_operation',
    onRetry: (attempt) => {
      if (addToast) {
        addToast(
          `Stock ocupado, reintentando (${attempt}/3)...`,
          'info'
        );
      }
    },
  });
}

/**
 * Retry espec√≠fico para offline sync
 * M√°s tolerante (5 retries) porque offline puede tener m√°s latencia
 */
export async function retryOfflineSync<T>(
  rpcCall: () => Promise<{ data: T | null; error: any }>
): Promise<{ data: T | null; error: any }> {
  return retryRpc(rpcCall, {
    maxRetries: 5,
    baseDelay: 500,
    maxDelay: 5000,
  });
}
